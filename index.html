<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TransportBench">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TransportBench</title>


  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link rel="icon" type="image/x-icon" href="./static/images/transportBenchlogo.webp">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/bulma-carousel.js"></script>
  <style>
    .results-carousel {
        width: 80%;       /* Set to your desired width */
        margin: 0 auto;   /* Center the carousel horizontally */
    }

  </style>
<style>
  .slider-container {
    position: relative;
    width: 100%;
    max-width:1000px;
    margin: auto;
    overflow: hidden;
  }
  
  .slider-wrapper {
    display: flex;
    transition: transform 0.3s ease-out;
  }
  
  .slider-item {
  width: 100%; /* 让每个 .slider-item 填满 .slider-wrapper */
  height: 100%; /* 让每个 .slider-item 填满 .slider-wrapper */
  display: flex; /* 使用 Flexbox 布局来居中内容 */
  justify-content: center; /* 水平居中内容 */
  align-items: center; /* 垂直居中内容 */
  flex-shrink: 0; /* 防止 flex 子元素缩小 */
}

/* 如果 .slider-item 包含图片 */
.slider-item img {
  width: 100%; /* 宽度填满 .slider-item */
  height: auto; /* 高度自适应以保持图片比例 */
  object-fit: cover; /* 覆盖整个区域，可能会剪裁某些部分 */
}
  
  button {
    position: absolute;
    top: 50%;
    transform: translateY(-50%);
    background-color: #333;
    color: white;
    border: none;
    padding: 10px 10px;
    cursor: pointer;
    z-index: 2;
  }
  
  .left-btn {
    left: 10px;
  }
  
  .right-btn {
    right: 10px;
  }
  
  </style>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.usmanahmedsyed.com/">Usman Syed</a><sup>1</sup>,</span>
              <a href="https://yfouyang.cee.illinois.edu/students/">Ethan Light</a><sup>1</sup>,</span>
              <a href="https://sites.google.com/view/guoxingang">Xingang Guo</a><sup>1</sup>,</span>
              <a href="https://www.huan-zhang.com/">Huan Zhang</a><sup>1</sup>,</span>
              <a href="https://lianhui.ucsd.edu/">Lianhui Qin</a><sup>2</sup>,</span>
              <a href="https://cee.illinois.edu/directory/profile/yfouyang">Yanfeng Ouyang</a><sup>1</sup>,</span>
              <a href="https://binhu7.github.io/">Bin Hu</a><sup>1</sup>,</span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois Urbana-Champaign</span>
            <span class="author-block"><sup>2</sup>University of California San Diego</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2408.08302"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/AGI4Engineering/TransportBench/tree/991ad69aa4956470603fd960feb0cc289cb8600f/TransportBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>TransportBench</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 in 
            solving some selected undergraduate-level transportation engineering problems. We introduce TransportBench, a benchmark dataset that includes a sample of transportation engineering problems on 
            a wide range of subjects in the context of planning, design, management, and control of transportation systems. This dataset is used by human experts to evaluate the capabilities of various commercial 
            and open-sourced LLMs, especially their accuracy, consistency, and reasoning behaviors, in solving transportation engineering problems. Our comprehensive analysis uncovers the unique strengths and 
            limitations of each LLM, e.g. our analysis shows the impressive accuracy and some unexpected inconsistent behaviors of Claude 3.5 Sonnet and Claude 3 Opus in solving TransportBench problems. Our study 
            marks a thrilling first step toward harnessing artificial general intelligence for complex transportation challenges.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="content">
     <h3>TransportBench Dataset</h3>
    <p>We introduce <strong>TransportBench</strong>,  a collection of 140 undergraduate problems that span a broad spectrum of topics related to transport engineering. TransportBench consists of both the <strong>true or false</strong> problems and the general <strong>Q&A</strong> problems. We
summarize the statistics of our TransportBench dataset for each topic as below.</p>
      </div>
    <!-- Summary of the work -->
     <div class="content">
    <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/dataset_overview.png"
           style="width: 100%; max-width: 750px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
    </div>
    <!-- Explanation of the diagram -->
    <div class="content" style="margin-top: 20px;">
    <ul>
        <li>TransportBench comprises 140 problems sourced from a junior-level introductory course CEE 310 - Transportation Engineering and a senior-level focused course CEE 418 - Public Transportation Systems.</li>
        <li>Each problem is human crafted by the domain expert Prof. Yanfeng Ouyang.</li>
    </ul>
      <p> Here we show two representative examples extracted from TransportBench
            <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/sampled_example.png"
           style="width: 100%; max-width: 1000px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
    </div>
    </div>
  </div>
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="content">
     <h3>Evaluating Accuracy of Leading LLMs on TransportBench</h3>
    <p>We evaluate the accuracy of leading LLMs such as GPT-4, GPT-4o, Claude 3 Opus, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3 (70B) and Llama 3.1 (405B) 
      on TransportBench via zero-shot pormpting strategy through human expert annotation. Our main evaluation
      metric is Accuracy (ACC), defined as the proportion of instances where the LLMs correctly solve the given problems. The results are reported as below.</p>
      </div>
    <!-- Summary of the work -->
     <div class="content">
    <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/table2.png"
           style="width: 100%; max-width: 1200px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
    </div>
      <div class="content has-text-justified">
        <ul>
          <li>Claude 3.5 Sonnet achieves the best ACC for most topics and the entire TransportBench dataset.</li>
          <li>Gemini 1.5 Pro, GPT-4o, and Claude 3 Opus all demonstrate competitive performance.</li>
          <li>The open-source model Llama 3.1 has reached the level of the commercial model GPT-4.</li>
        </ul>
       </div>
  </div>
</div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary of the work -->
    <div class="content">
      <h3>CEE 310 vs. CEE 418 and True/False vs General Q&A</h3>
      <p>It is interesting to investigate the impact of problem difficulty levels. The problems of TransportBench sourced from two classes: 
        CEE 310 and CEE 418. CEE 310 is an introductory course that covers a very broad range of topics in transportation engineering, while 
        CEE 418 is considered as a more advanced and more focused follow-up course (whose prerequisite is CEE 310). The following table shows 
        the ACC of these two courses.</p>
      <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/table3.png"
           style="width: 100%; max-width: 700px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
      </div>
      <div class="content has-text-justified">
        <ul>
          <li>All the LLMs have lower ACC on CEE 418, and higher ACC on CEE 310.</li>
          <li>Claude 3.5 Sonnet significantly outperforms all the other LLMs on CEE 418, demonstrating its superior capabilities in handling more 
            advanced topics in transportation engineering.</li>
        </ul>
       </div>
      <p> We have studied how the problem type affects the LLM performance. The TransportBench consists of True or False problems and general Q&A problems. 
        Intuitively, True or False problems are easier than more general Q&A problems. We report the ACC of the seven evaluated LLMs for each problem type 
        in the above Table. The ACC results for True/False vs General Q&A shows: <\p>
            <div class="content has-text-justified">
        <ul>
          <li>Most LLMs have shown consistently lower ACC scores for general Q&A problems compared to True or False problems.</li>
          <li>Claude 3.5 Sonnet achieves similar ACC for both general Q&A problems (71.6%) and True or False problems (72.6%).</li>
        </ul>
       </div> 

   </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary of the work -->
    <div class="content">
      <h3>Zero-shot Consistency on True/False Problems</h3>
      <p>Consistency refers to uniform, reliable, and logically coherent responses that maintain the
same principles and reasoning across different inquiries. We have studied zero-shot consistency of LLMs 
        on the True or False problem. In this setting, we independently test five trials of each problem in the zero-shot setting. 
        We used two metrics to quantify the zero-shot consistency: (i) Mixed Response Rate (MRR), which is the percentage of the True 
        or False problems that received mixed responses (non-identical answers) in any of the five trials; and (ii) aggregate ACC, which is 
        the proportion of the trials where LLMs give the correct true or false label over the total 73 × 5 = 365 trials.</p>
      <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/table4.png"
           style="width: 100%; max-width: 440px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
      </div>
      <div class="content has-text-justified">
        <ul>
          <li>Llama 3 achieves the lowest MRR. However, the aggregate ACC for Llama 3 is also the lowest which suggests it has strong bias and consistently 
            generate incorrect answers. Our study has shown Llama 3 to reports True for almost 90% of the total problem trials.</li>
          <li>Claude 3.5 Sonnet achieves the highest aggregate ACC while maintaining a very low MRR making it the state-of-the art LLM 
            in terms of zero-shot consistency for TransportBench. </li>
        </ul>
       </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary of the work -->
    <div class="content">
      <h3>Consistency under self-checking prompt</h3>
      <p>The LLM literature reports that sometimes LLMs can correct their mistakes if given simple self-checking prompts, such as "carefully check your solutions". 
      We examine whether LLMs will generate consistent answers and reasoning when they are prompted to double check their original answers. 
        We provide a complementary perspective on consistency of LLMs using two metrics. The first metric is self-checking accuracy (denoted as ACC-<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mover>
    <mi>s</mi>
    <mo>&#x0305;</mo>
  </mover>
</math>), which 
        quantifies the instances in which LLMs give correct answers after the self-checking process. The second metric is the number of the True or False problems 
        in which the LLMs flip the original correct answers to wrong ones. For a consistent LLM, we ideally want ACC-<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mover>
    <mi>s</mi>
    <mo>&#x0305;</mo>
  </mover>
</math> to be higher than ACC and the number 
        of incorrect flips to be low.</p>
      <div style="text-align: center; margin-top: 20px;"> <!-- Center align the image container -->
      <img src="./static/images/table5.png"
           style="width: 100%; max-width: 640px; height: auto; display: block; margin: 0 auto;" <!-- Make the image responsive and centered -->
      </div>
      <div class="content has-text-justified">
        <ul>
          <li>The self-checking prompts proved useful for GPT-4o and GPT-4 to boost their accuracy. The number of incorrect flips for GPT-4 and GPT-4o is very low 
            thus showing these models to be consistent. </li>
          <li>Given self-checking prompts, Claude 3.5 Sonnet is still more consistent than Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1, but less consistent 
            than GPT-4 and GPT-4o.</li>
        </ul>
       </div>
    </div>
  </div>
</section> 
  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary of the work -->
    <div class="content">
      <h3>Examples</h3>
      <p>
      Here are selected examples in TransportBench:
      </p>
    </div>
    
    <!-- Large plot display -->
    <div class="slider-container">
      <div class="slider-wrapper">
        <div class="slider-item">
          <img src="./static/images/example1.png" alt="Image 1">
        </div>
        <div class="slider-item">
          <img src="./static/images/example2.png" alt="Image 2">  
        </div>
        <div class="slider-item">
          <img src="./static/images/example3.png" alt="Image 3">
        </div>
        <div class="slider-item">
          <img src="./static/images/example4.png" alt="Image 4">
        </div>
           <div class="slider-item">
          <img src="./static/images/example5.png" alt="Image 5">
        </div>
         <div class="slider-item">
          <img src="./static/images/example6.png" alt="Image 6">
        </div>
        <div class="slider-item">
          <img src="./static/images/example7.png" alt="Image 6">
        </div>
        <div class="slider-item">
          <img src="./static/images/example1.png" alt="Image 6">
        </div>
        <div class="slider-item">
          <img src="./static/images/example2.png" alt="Image 6">
        </div>
        <div class="slider-item">
          <img src="./static/images/example3.png" alt="Image 6">
        </div>
        <div class="slider-item">
          <img src="./static/images/example4.png" alt="Image 6">
        </div>
      </div>
      <button class="left-btn"><</button>
      <button class="right-btn"> > </button>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Usman2024TransportBench,
  author    = {Usman, Syed and Ethan, Light and Xingang, Guo and Huan, Zhang and Lianhui, Qin and Yanfeng, Ouyang and Bin, Hu},
  title     = {Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors},
  journal   = {https://arxiv.org/abs/2408.08302},
  year      = {2024},
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<!-- <script>
  const sliderWrapper = document.querySelector('.slider-wrapper');
  const sliderItems = document.querySelectorAll('.slider-item');
  let currentIndex = 0;

  document.querySelector('.left-btn').addEventListener('click', () => {
    if (currentIndex > 0) {
      currentIndex--;
      updateSliderPosition();
    }
  });

  document.querySelector('.right-btn').addEventListener('click', () => {
    if (currentIndex < sliderItems.length - 1) {
      currentIndex++;
      updateSliderPosition();
    }
  });

  function updateSliderPosition() {
    const newTransformValue = -currentIndex * 100; // Assuming each slide is 100% of the container width
    sliderWrapper.style.transform = `translateX(${newTransformValue}%)`;
  }
</script> -->


<script>
  const sliderWrapper = document.querySelector('.slider-wrapper');
  const sliderItems = document.querySelectorAll('.slider-item');
  let currentIndex = 0;

  document.querySelector('.left-btn').addEventListener('click', () => {
    // Modify this to go to the last image if currently at the first image
    if (currentIndex > 0) {
      currentIndex--;
    } else {
      currentIndex = sliderItems.length - 1; // Go to the last image
    }
    updateSliderPosition();
  });

  document.querySelector('.right-btn').addEventListener('click', () => {
    // Reset currentIndex to 0 if on the last image, otherwise increment
    if (currentIndex < sliderItems.length - 1) {
      currentIndex++;
    } else {
      currentIndex = 0; // Reset to the first image
    }
    updateSliderPosition();
  });

  function updateSliderPosition() {
    const newTransformValue = -currentIndex * 100; // Assuming each slide is 100% of the container width
    sliderWrapper.style.transform = `translateX(${newTransformValue}%)`;
  }
</script>


</body>
</html>
